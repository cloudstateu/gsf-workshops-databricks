{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+------+\n",
      "|EmployeeName|Department|Salary|\n",
      "+------------+----------+------+\n",
      "|       James|     Sales|  3000|\n",
      "|     Michael|     Sales|  4600|\n",
      "|      Robert|        IT|  4100|\n",
      "|       Maria|   Finance|  3000|\n",
      "|       James|     Sales|  3000|\n",
      "|       Scott|   Finance|  3300|\n",
      "|         Jen|   Finance|  3900|\n",
      "|        Jeff| Marketing|  3000|\n",
      "|       Kumar| Marketing|  2000|\n",
      "|        Saif|     Sales|  4100|\n",
      "+------------+----------+------+\n",
      "\n",
      "+----------+-------------+\n",
      "|Department|AverageSalary|\n",
      "+----------+-------------+\n",
      "|     Sales|       3675.0|\n",
      "|        IT|       4100.0|\n",
      "|   Finance|       3400.0|\n",
      "| Marketing|       2500.0|\n",
      "+----------+-------------+\n",
      "\n",
      "+------------+----------+------+\n",
      "|EmployeeName|Department|Salary|\n",
      "+------------+----------+------+\n",
      "|     Michael|     Sales|  4600|\n",
      "|      Robert|        IT|  4100|\n",
      "|       Scott|   Finance|  3300|\n",
      "|         Jen|   Finance|  3900|\n",
      "|        Saif|     Sales|  4100|\n",
      "+------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import PySpark SQL functions\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg\n",
    "\n",
    "# Initialize a SparkSession in Databricks\n",
    "spark = SparkSession.builder.appName(\"DatabricksDataFrameExample\").getOrCreate()\n",
    "\n",
    "# Sample data\n",
    "data = [(\"James\", \"Sales\", 3000),\n",
    "        (\"Michael\", \"Sales\", 4600),\n",
    "        (\"Robert\", \"IT\", 4100),\n",
    "        (\"Maria\", \"Finance\", 3000),\n",
    "        (\"James\", \"Sales\", 3000),\n",
    "        (\"Scott\", \"Finance\", 3300),\n",
    "        (\"Jen\", \"Finance\", 3900),\n",
    "        (\"Jeff\", \"Marketing\", 3000),\n",
    "        (\"Kumar\", \"Marketing\", 2000),\n",
    "        (\"Saif\", \"Sales\", 4100)]\n",
    "\n",
    "# Column names\n",
    "columns = [\"EmployeeName\", \"Department\", \"Salary\"]\n",
    "\n",
    "# Creating DataFrame\n",
    "df = spark.createDataFrame(data, schema=columns)\n",
    "\n",
    "# Show the DataFrame\n",
    "df.show()\n",
    "\n",
    "# Basic DataFrame operations\n",
    "\n",
    "# Group by \"Department\" and calculate average salary\n",
    "avg_salary = df.groupBy(\"Department\").agg(avg(col(\"Salary\")).alias(\"AverageSalary\"))\n",
    "avg_salary.show()\n",
    "\n",
    "# Filter employees with salary greater than 3000\n",
    "high_earners = df.filter(col(\"Salary\") > 3000)\n",
    "high_earners.show()\n",
    "\n",
    "# Stop the SparkSession\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
